{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "from selenium import webdriver\n",
    "\n",
    "from selenium.webdriver.support.select import Select\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It has a series of steps that you need to scrap:\n",
    "- open the chrome driver\n",
    "- open the linkedin jobs url\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.linkedin.com/jobs/search/?currentJobId=3477276853&geoId=106677219&keywords=data%20analyst&location=Waterloo%2C%20Ontario%2C%20Canada&refresh=true\"\n",
    "driver_path = \"./chromedriver\"\n",
    "\n",
    "driver = webdriver.Chrome(executable_path=driver_path)\n",
    "driver.get(url)\n",
    "driver.implicitly_wait(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_searchbar(job_titles,location):\n",
    "    # locate the search bar\n",
    "    searchbar_job = driver.find_element_by_name(\"keywords\")\n",
    "    searchbar_location = driver.find_element_by_name(\"location\")\n",
    "    # clear the default text\n",
    "    searchbar_job.clear()\n",
    "    searchbar_location.clear()\n",
    "    # send in newtext\n",
    "    searchbar_job.send_keys(job_titles)\n",
    "    searchbar_location.send_keys(location)\n",
    "\n",
    "    time.sleep(2)\n",
    "    # press enter in the search bar\n",
    "    searchbar_job.send_keys(Keys.RETURN)\n",
    "\n",
    "update_searchbar(job_titles=\"data engineer\",location=\"toronto, ontario, canada\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to add the filtering condition\n",
    "- any time\n",
    "- location\n",
    "- experience level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_job_filtering(button_css,filter_condition_css,done_css):\n",
    "    \"\"\"\n",
    "    apply the job filtering condition based on css selector of the web elements.\n",
    "    You need to use CSS selector to select it\n",
    "    Args:\n",
    "        button_css (_type_): _description_\n",
    "        filter_condition_css (_type_): _description_\n",
    "        done_css (_type_): _description_\n",
    "    \"\"\"\n",
    "    # locate and click the filter time button\n",
    "    button_filter_time = driver.find_element_by_css_selector(button_css)\n",
    "    driver.execute_script(\"arguments[0].click();\",button_filter_time)\n",
    "    time.sleep(1)\n",
    "    # locate and click the past 24 hours\n",
    "    filter_time_past_24 = driver.find_element_by_css_selector(filter_condition_css)\n",
    "    driver.execute_script(\"arguments[0].click();\",filter_time_past_24)\n",
    "    time.sleep(1)\n",
    "    # locate and click the \"done\" button\n",
    "    button_done = driver.find_element_by_css_selector(done_css)\n",
    "    driver.execute_script(\"arguments[0].click();\",button_done)\n",
    "    time.sleep(1)\n",
    "\n",
    "# apply date filtering to the past month\n",
    "apply_job_filtering(button_css = \"form#jserp-filters li:nth-child(1) > div > div > button\",\n",
    "                    filter_condition_css = \"form#jserp-filters li:nth-child(1) > div > div > div > div > div > div:nth-child(3) > label\",\n",
    "                    done_css= \"form#jserp-filters li:nth-child(1) > div > div > div > button\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you need to infintely scroll down the pages and click load more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scroll_down(number_of_iterations = 50):\n",
    "    \"\"\"\n",
    "    indefinitely scroll down until no jobs could be loaded\n",
    "    Args:\n",
    "        number_of_iterations (_type_): _description_\n",
    "    \"\"\"\n",
    "    # i dummy iterator, the program time is actually controled by the time.sleep()\n",
    "    i = 0\n",
    "    while i <= number_of_iterations:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        \n",
    "        i += 1\n",
    "\n",
    "        try:\n",
    "            # find th button\n",
    "            button_see_jobs = driver.find_element_by_class_name(\"infinite-scroller__show-more-button\")        \n",
    "            # click it\n",
    "            driver.execute_script(\"arguments[0].click();\",button_see_jobs)\n",
    "            \n",
    "            #3 secs grace period for it to load\n",
    "            time.sleep(2)\n",
    "        except:\n",
    "            # not finding the button, wait for three secs and continue\n",
    "            pass\n",
    "            time.sleep(1)\n",
    "\n",
    "scroll_down()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you should have scroll down to the very bottom of the pages with no more jobs available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_name = []\n",
    "job_titles = []\n",
    "links = []\n",
    "\n",
    "for i in range(300):\n",
    "    try:\n",
    "        # grab the necessary info\n",
    "        link = driver.find_elements_by_class_name('hidden-nested-link')[i].get_attribute('href')\n",
    "        # link = driver.find_elements_by_class_name('base-card__full-link')[i].get_attribute('href')\n",
    "\n",
    "        job_title = driver.find_elements_by_class_name('base-search-card__title')[i].text\n",
    "        company = driver.find_elements_by_class_name('base-search-card__subtitle')[i].text\n",
    "        # append it to a list\n",
    "        company_name.append(company)\n",
    "        job_titles.append(job_title)\n",
    "        links.append(link)\n",
    "    except IndexError:\n",
    "        print(\"job done!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>job_title</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lyft</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>https://ca.linkedin.com/jobs/view/data-enginee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Think Research</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>https://ca.linkedin.com/jobs/view/data-enginee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Borrowell</td>\n",
       "      <td>Senior Data Engineer</td>\n",
       "      <td>https://ca.linkedin.com/jobs/view/senior-data-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Points (a Plusgrade company)</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>https://ca.linkedin.com/jobs/view/data-enginee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Credit Pros</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>https://ca.linkedin.com/jobs/view/data-enginee...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        company             job_title  \\\n",
       "0                          Lyft         Data Engineer   \n",
       "1                Think Research         Data Engineer   \n",
       "2                     Borrowell  Senior Data Engineer   \n",
       "3  Points (a Plusgrade company)         Data Engineer   \n",
       "4               The Credit Pros         Data Engineer   \n",
       "\n",
       "                                                link  \n",
       "0  https://ca.linkedin.com/jobs/view/data-enginee...  \n",
       "1  https://ca.linkedin.com/jobs/view/data-enginee...  \n",
       "2  https://ca.linkedin.com/jobs/view/senior-data-...  \n",
       "3  https://ca.linkedin.com/jobs/view/data-enginee...  \n",
       "4  https://ca.linkedin.com/jobs/view/data-enginee...  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"company\"] = company_name\n",
    "df[\"job_title\"] = job_titles\n",
    "df[\"link\"] = links\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is still has the problems that some link are missing. Instead of pulling job title from main page, we should just scrap the link and scrape your company, jobtitle information there. It should solve the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df.to_csv(\"./test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "linkedin-scrapper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9d032c5f91033def2e2da1dd81427c1088d020d29e232a92efdec61b8349a0c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
